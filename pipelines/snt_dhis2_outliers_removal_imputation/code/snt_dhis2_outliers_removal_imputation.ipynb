{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26675878-1d15-4b17-9f93-b92d396b82fc",
   "metadata": {},
   "source": [
    "# Outliers **removal** and **imputation** \n",
    "\n",
    "**Input**:\n",
    "* DHIS2 **routine data** (formatted and aligned as per ush).\n",
    "    * From Dataset **SNT_DHIS2_FORMATTED** as `XXX_routine.parquet` \n",
    "* Table of outliers: table containing only values flagged as outliers, based on 1 outliers detection method. This input is a choice of the user (see parameters)\n",
    "    * From Dataset **DHIS2_OUTLIERS_DETECTION** as `XXX_outlier_<method_name>.parquet`\n",
    "\n",
    "**Output**:\n",
    "* DHIS2 **routine data _without_ outliers**: outliers are simply removed.\n",
    "    * To Dataset **DHIS2_OUTLIERS_REMOVAL_IMPUTATION** as `XXX_routine_removed-outlier-<method_name>.parquet` (e.g., `COD_routine_outlier_mean3sd_removed.parquet`)\n",
    "* DHIS2 **routine data** _without_ outliers &  **_with_ imputed values**: values flagged as outliers are replaced by imputed values.\n",
    "    * To Dataset **DHIS2_OUTLIERS_REMOVAL_IMPUTATION** as `XXX_routine_removed-outlier-<method_name>_imputed.parquet`\n",
    "    * Imputation uses the moving avergae as per:\n",
    "  ```\n",
    "  rollapply(IMPUTATION, # zoo::rollapply()\n",
    "                               width = 3, \n",
    "                               FUN = function(x) ceiling(mean(x, na.rm = TRUE)), \n",
    "                               fill = NA, \n",
    "                               align = \"center\")\n",
    "  ```\n",
    "\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19516e45-1b34-4e64-a32f-7e3601973275",
   "metadata": {},
   "source": [
    "**Parameters**:\n",
    "* **How to treat outliers**:\n",
    "    * remove\n",
    "    * remove & replace with impuated values\n",
    "<br>\n",
    "<br>\n",
    "* **Choice of outliers detection method**:\n",
    "    * mean _n_ * SD\n",
    "    * median _n_ * MAD\n",
    "    * _n_ * IQR\n",
    "    * Magic Glasses \"Partial\": file called `*_outlier_magic_glasses_partial_*` (MAD15 >> MAD10)\n",
    "    * Magic Glasses \"Complete\": file called `*_outlier_magic_glasses_complete_*` (MAD15 >> MAD10 >> seasonal5 >> seasonal3)\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ce9ba-0e34-4d29-97f6-7ac04eeb2f4b",
   "metadata": {},
   "source": [
    "## 0. Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffc431-c82a-4c78-88b4-d31668aa2e6d",
   "metadata": {},
   "source": [
    "üëá these are now ‚ö°**pipeline parameters**‚ö°!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfeeef-e5e7-42c0-9aff-d63ead982231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER_METHOD <- \"mean3sd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a488bd8-bdc4-4a8e-bf6e-5199e60736aa",
   "metadata": {},
   "source": [
    "#### Set Default values **if _not_ provided by pipeline**\n",
    "This makes the execution flexible and \"safe\": nb can be run manually from here or be executed via pipeline, without having to change anything in the code!\n",
    "\n",
    "üö® **Important**: must use the `if (!exists(\"PARAMETER_NAME\")) { ... }` formula to avoid over writing the parameters injected by Papermill (into special cell a top of nb, see OUTPUT nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777de1ea-ebb3-45ff-9787-11c07b74b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BACKUP VALUE: name of config file to use\n",
    "if (!exists(\"CONFIG_FILE_NAME\")) {\n",
    "  CONFIG_FILE_NAME <- \"SNT_config.json\"  # Default if not provided by pipeline\n",
    "}\n",
    "\n",
    "# Set BACKUP VALUE: \n",
    "if (!exists(\"OUTLIER_METHOD\")) {\n",
    "  OUTLIER_METHOD <- \"median3mad\"  # other options: \"mean3sd\", \"iqr1-5\", \"magic_glasses_partial\", \"magic_glasses_complete\" \n",
    "}                              # ‚ö†Ô∏è TO DO: in pipeline.py, make this choice dynamic based on files available in Dataset (subset part of filename that indicates the method\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2d697-b807-42da-bdf8-04391d43282e",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49566506-75c7-42fd-a2fe-6250a8065267",
   "metadata": {},
   "source": [
    "### 1.1. Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9240711-421e-4284-b47b-834ea5967c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BACKUP VALUE: root path - NEVER CHANGE THIS!\n",
    "if (!exists(\"ROOT_PATH\")) {\n",
    "  ROOT_PATH <- \"/home/hexa/workspace\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53619a-d426-44b6-a5a7-df93ed5fd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT PATHS\n",
    "\n",
    "# Project folders\n",
    "CODE_PATH <- file.path(ROOT_PATH, 'code') # this is where we store snt_functions.r and snt_utils.r\n",
    "CONFIG_PATH <- file.path(ROOT_PATH, 'configuration') # .json config file\n",
    "DATA_PATH <- file.path(ROOT_PATH, 'data') # same as in Datasets but /data/ gets over written every time a new version of Datasets is pushed\n",
    "\n",
    "print(CODE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74225b-b8a6-4073-9c67-b17f93873a89",
   "metadata": {},
   "source": [
    "### 1.2. Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c985de-bacf-44a4-86e9-17e4b4b8ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "source(file.path(CODE_PATH, \"snt_utils.r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4122035-18e7-4ddf-a136-d003fd7225ef",
   "metadata": {},
   "source": [
    "### 1.3. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1403c-9984-4418-99fe-ad156a315629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List required pcks \n",
    "required_packages <- c(\"arrow\", # for .parquet\n",
    "                       \"tidyverse\",\n",
    "                       \"stringi\", \n",
    "                       # \"sf\",\n",
    "                       # \"forecast\",\n",
    "                       \"zoo\",\n",
    "                       \"jsonlite\", \n",
    "                       \"httr\", \n",
    "                       \"reticulate\")\n",
    "\n",
    "# Execute function\n",
    "install_and_load(required_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae5738-f4d5-4758-8ee2-ce0ea3a8eac1",
   "metadata": {},
   "source": [
    "#### Set environment to load openhexa.sdk from the right path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be11fd-5281-4630-a142-afad4447aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment to load openhexa.sdk from the right path\n",
    "Sys.setenv(RETICULATE_PYTHON = \"/opt/conda/bin/python\")\n",
    "reticulate::py_config()$python\n",
    "openhexa <- import(\"openhexa.sdk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc81c3f-898c-49bf-a822-d96a24fd1054",
   "metadata": {},
   "source": [
    "### 1.4. Load and check `config` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768a17f-c083-45a2-936f-079a099d67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SNT config\n",
    "\n",
    "config_json <- tryCatch({\n",
    "        fromJSON(file.path(CONFIG_PATH, CONFIG_FILE_NAME)) # \"SNT_config.json\"\n",
    "    },\n",
    "    error = function(e) {\n",
    "        msg <- paste0(\"Error while loading configuration\", conditionMessage(e))  \n",
    "        cat(msg)   \n",
    "        stop(msg) \n",
    "    })\n",
    "\n",
    "msg <- paste0(\"SNT configuration loaded from  : \", file.path(CONFIG_PATH, CONFIG_FILE_NAME)) \n",
    "log_msg(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e046c-2074-48b9-95e4-dd8693118b39",
   "metadata": {},
   "source": [
    "#### **Checks for SNT mandatory configuration fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab185477-313d-499d-abc1-eb2235267282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK SNT configuration \n",
    "snt_config_mandatory <- c(\"COUNTRY_CODE\", \"DHIS2_ADMINISTRATION_1\", \"DHIS2_ADMINISTRATION_2\") \n",
    "\n",
    "for (conf in snt_config_mandatory) {\n",
    "    print(paste(conf, \":\", config_json$SNT_CONFIG[conf]))\n",
    "    if (is.null(config_json$SNT_CONFIG[[conf]])) {\n",
    "        msg <- paste(\"Missing configuration input:\", conf)\n",
    "        cat(msg)   \n",
    "        stop(msg)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1b2f4-a23b-4236-821e-562350a16963",
   "metadata": {},
   "source": [
    "#### **Save config fields as variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80fd69-bf14-4090-b08c-2b3389ea84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "COUNTRY_CODE <- config_json$SNT_CONFIG$COUNTRY_CODE\n",
    "ADMIN_1 <- toupper(config_json$SNT_CONFIG$DHIS2_ADMINISTRATION_1)\n",
    "ADMIN_2 <- toupper(config_json$SNT_CONFIG$DHIS2_ADMINISTRATION_2)\n",
    "\n",
    "# Which (aggregated) indicators to use to evaluate \"activity\" of an HF - for Reporting Rate method \"ANY\"\n",
    "DHIS2_INDICATORS <- names(config_json$DHIS2_DATA_DEFINITIONS$DHIS2_INDICATOR_DEFINITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f34bd2-d9b5-404b-b6f4-88415e31097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DHIS2_INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fbba0-f7ee-489a-93f6-705589d79eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed routine formatting columns\n",
    "# must keep&use `OU` as it contains unique ids (OU_NAME has homonimous values!)\n",
    "fixed_cols <- c('PERIOD', 'YEAR', 'MONTH', 'ADM1_ID', 'ADM2_ID', 'OU_ID') # keep ADMX_ID only! \n",
    "\n",
    "print(paste(\"Fixed routine data ('dhis2_routine') columns (always expected): \", paste(fixed_cols, collapse=\", \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8624e7-ca6a-4539-a385-604d471a497b",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3baacd-169b-4e28-9664-eac0bdf8c873",
   "metadata": {},
   "source": [
    "### 2.1. **Routine** data (DHIS2) \n",
    "already formatted & aggregated<br>\n",
    "(output of pipeline \"XXX\" and stored in Dataset \"**SNT_DHIS2_FORMATTED**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5973f-5044-4521-8ee0-1490a95a8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DHIS2 Dataset extract identifier\n",
    "dataset_name <- config_json$SNT_DATASET_IDENTIFIERS$DHIS2_DATASET_FORMATTED\n",
    "\n",
    "# Load file from dataset\n",
    "dhis2_routine <- tryCatch({ get_latest_dataset_file_in_memory(dataset_name, paste0(COUNTRY_CODE, \"_routine.parquet\")) }, \n",
    "                  error = function(e) {\n",
    "                      msg <- paste(\"Error while loading DHIS2 routine data file for: \" , COUNTRY_CODE, conditionMessage(e))  # log error message\n",
    "                      cat(msg)\n",
    "                      stop(msg)\n",
    "})\n",
    "\n",
    "msg <- paste0(\"DHIS2 routine data loaded from dataset : \", dataset_name, \" dataframe dimensions: \", paste(dim(dhis2_routine), collapse=\", \"))\n",
    "log_msg(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05cf154-4633-4b0f-b94d-33ae3e526883",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(dhis2_routine, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e919fc-1354-436e-bc60-6239cff96083",
   "metadata": {},
   "source": [
    "#### Checks on routine data cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b180fb-b3b3-4e8f-a5e2-acb58c626546",
   "metadata": {},
   "source": [
    "**fixed_cols**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eb80d-b1df-4149-b124-1176f74e3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all \"fixed\" cols are present in dhis2_routine\n",
    "\n",
    "actual_cols <- colnames(dhis2_routine) # dhis2_routine\n",
    "missing_cols <- setdiff(fixed_cols, actual_cols) # Columns in fixed_cols but not in actual_cols)\n",
    "\n",
    "# Check if all required columns are present\n",
    "all_present <- length(missing_cols) == 0\n",
    "\n",
    "if (all_present) { \n",
    "  log_msg(paste0(\"Success: The 'dhis2_routine' tibble contains all the expected 'fixed' columns: \",\n",
    "                paste(fixed_cols, collapse = \", \"), \".\"))\n",
    "} else {\n",
    "    log_msg(paste0(\n",
    "      \"üõë Missing Columns: The following required columns are NOT present in 'dhis2_routine': \",\n",
    "      paste(missing_cols, collapse = \", \"),\n",
    "      \".\"\n",
    "    ))\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681368ab-4cb5-4f78-b461-2ce368ed47f3",
   "metadata": {},
   "source": [
    "**DHIS2_INDICATORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f10e4-5d4c-46e1-9440-b6d026828bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all \"DHIS2_INDICATORS\" cols are present in dhis2_routine\n",
    "\n",
    "actual_cols <- colnames(dhis2_routine) # dhis2_routine\n",
    "missing_cols <- setdiff(DHIS2_INDICATORS, actual_cols) # Columns in fixed_cols but not in actual_cols)\n",
    "all_present <- length(missing_cols) == 0\n",
    "\n",
    "if (all_present) { \n",
    "  log_msg(paste0(\"Success: The 'dhis2_routine' tibble contains all the expected 'DHIS2_INDICATORS' columns: \",\n",
    "                paste(fixed_cols, collapse = \", \"), \".\"))\n",
    "} else {\n",
    "    log_msg(paste0(\n",
    "      \"üö® Missing Columns: The following columns for DHIS2 INDICATORS are NOT present in 'dhis2_routine': \",\n",
    "      paste(missing_cols, collapse = \", \"),\n",
    "      \". üö® Looks like the \", CONFIG_FILE_NAME, \" file was modified after extraction. üö® The analysis will continue WITHOUT the missing indicators.\"\n",
    "    )\n",
    "                   )\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36be84f-4be9-4339-9440-22cf5ea2a611",
   "metadata": {},
   "source": [
    "### 2.2. Ouliers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f057d5-02bf-4889-a1be-bd1e9a5f2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DHIS2 Dataset extract identifier\n",
    "dataset_name_outliers <- config_json$SNT_DATASET_IDENTIFIERS$DHIS2_OUTLIERS_DETECTION\n",
    "\n",
    "# Load file from dataset\n",
    "outliers <- tryCatch({ get_latest_dataset_file_in_memory(dataset_name_outliers, paste0(COUNTRY_CODE, \"_outlier_\", OUTLIER_METHOD, \".parquet\")) }, # COD_outlier_iqr1-5.parquet\n",
    "                  error = function(e) {\n",
    "                      msg <- paste(\"Error while loading DHIS2 routine data file for: \" , COUNTRY_CODE, conditionMessage(e))  # log error message\n",
    "                      cat(msg)\n",
    "                      stop(msg)\n",
    "})\n",
    "\n",
    "msg <- paste0(\"Table with outlier values loaded from dataset : \", dataset_name_outliers, \" dataframe dimensions: \", paste(dim(outliers), collapse=\", \"))\n",
    "log_msg(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d809018-c01d-43c1-bf2a-56d7a8d162a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(outliers))\n",
    "head(outliers, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f5cd7-86ce-49ae-b498-59b645563491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3691ddc6-e268-47c2-805f-eab8f2ef119c",
   "metadata": {},
   "source": [
    "# 3. Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c396e36-b233-4c37-9b66-2ab7e089210b",
   "metadata": {},
   "source": [
    "### Pivot routine data \n",
    "Make long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ad78b-5531-42be-a407-55e6c9e3cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot `indicator_cols` = all columns except fixed columns\n",
    "# indicator_cols <- colnames(dhis2_routine)[!(names(dhis2_routine) %in% fixed_cols)] # problem: includes `OU_NAME`\n",
    "indicator_cols <- names(config_json$DHIS2_DATA_DEFINITIONS$DHIS2_INDICATOR_DEFINITIONS) # instead, just extract list of indicators colsnames based on config file\n",
    "\n",
    "# pivot routine data\n",
    "dhis2_routine_long <- dhis2_routine %>%\n",
    "    pivot_longer(#cols = all_of(indicator_cols),\n",
    "                 cols = any_of(indicator_cols),  # ‚ö†Ô∏è TEMP switch as config.json was changed but not extracted data (some cols are missing) ‚ö†Ô∏è\n",
    "                 names_to = \"INDICATOR\",\n",
    "                 values_to = \"VALUE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0823e-e29d-43e3-b5da-f2fafbe5e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(dhis2_routine_long))\n",
    "head(dhis2_routine_long,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e59345-2f12-41c6-b3ca-c197220e933c",
   "metadata": {},
   "source": [
    "### Format the **outliers** table: rename col `OUTLIER_<method_name>` to `OUTLIER`\n",
    "üö® Necessary because the **col flagging** the **outlier** values has a **different name** for each outlier detetcion method output <br>\n",
    "(üí° consider changing this upstream ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ceb7c4-9e9f-42d9-80ea-9df845c95a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers <- outliers %>%\n",
    "  rename_with(~ \"OUTLIER\", starts_with(\"OUTLIER_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e0cd1-d142-46ff-9010-a32c5ea1a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea772d-6d82-4da9-93d6-a2791967710e",
   "metadata": {},
   "source": [
    "### Join outliers on routine data\n",
    "This adds the col `OUTLIER_*` to the (pivoted long) routine data.\n",
    "Here, `NA`s are assigned to values that are not outliers. These `NA`s need to be replaced by `FALSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db992ac6-8460-4cb5-be6f-562516ca40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join\n",
    "# merged_data <- left_join(dhis2_routine_long, outliers, \n",
    "#                          by = c(fixed_cols, \"INDICATOR\", \"VALUE\")) \n",
    "\n",
    "dhis2_routine_long_outliers <- left_join(dhis2_routine_long, outliers, \n",
    "                                         by = c(fixed_cols, \"INDICATOR\", \"VALUE\")) \n",
    "\n",
    "# In col `OUTLIER_*`, replace `NA`s with `FALSE`\n",
    "# merged_data <- merged_data %>%\n",
    "# mutate(OUTLIER = if_else(is.na(OUTLIER), FALSE, OUTLIER))\n",
    "\n",
    "dhis2_routine_long_outliers <- dhis2_routine_long_outliers %>%\n",
    "mutate(OUTLIER = if_else(is.na(OUTLIER), FALSE, OUTLIER))\n",
    "\n",
    "print(dim(dhis2_routine_long_outliers))\n",
    "head(dhis2_routine_long_outliers, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead21be0-a54a-4c1b-bd94-93fca02610dd",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "This was not in the original/older code (BFA). Added now as option: just remove all values flagged as outliers.\n",
    "<br>\n",
    "Later: **Export** as `XXX_routine_outlier-<method_name>_removed`.csv/parquet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931d208-54b9-4fe3-8cac-623888ccffb3",
   "metadata": {},
   "source": [
    "#### **Remove** outliers & pivot wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8a6d0-5e84-4c77-a5f1-34d8acf284f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was `routine_removed_outliers` now `dhis2_routine_long_outliers_removed`\n",
    "dhis2_routine_long_outliers_removed <- dhis2_routine_long_outliers %>%\n",
    "filter(OUTLIER == FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7005b-7c87-43ab-9cc9-c4d65193043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(dhis2_routine_long_outliers_removed))\n",
    "head(dhis2_routine_long_outliers_removed, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd3896-76b2-4abe-b4b4-8fd1be72b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When removing outliers, how many values are removed (= nr of values converted to NA)\n",
    "nr_of_outliers <- dhis2_routine_long_outliers %>% filter(OUTLIER == TRUE) %>% nrow()\n",
    "nr_of_values <- dhis2_routine_long_outliers %>% nrow()\n",
    "perc_outliers <- round(nr_of_outliers/nr_of_values * 100, 2)\n",
    "\n",
    "msg <- paste0(\n",
    "  \"Using outliers detection method *\", OUTLIER_METHOD,\n",
    "  \"*. Identified and removed \", nr_of_outliers,\n",
    "  \" outliers (\", perc_outliers, \"% of values).\"\n",
    ")\n",
    "\n",
    "# Log the message\n",
    "if (!is.null(openhexa$current_run)) {\n",
    "  openhexa$current_run$log_info(msg)\n",
    "}\n",
    "\n",
    "# log_msg(msg) # Also print to console - this makes it printed twice in the pipeline log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34cde8-54e0-44fb-8f4d-5aff48350998",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhis2_routine_outliers_removed <- dhis2_routine_long_outliers_removed %>%\n",
    "select(all_of(fixed_cols), INDICATOR, VALUE) %>% # names() #  'PERIOD''YEAR''MONTH''ADM1_ID''ADM2_ID''OU''INDICATOR''VALUE'\n",
    "pivot_wider(names_from = \"INDICATOR\", values_from = \"VALUE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0864990-e45d-4739-98a2-ec2f2893cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(dhis2_routine_outliers_removed))\n",
    "head(dhis2_routine_outliers_removed, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b897f-4397-44a9-9d2d-bfc0f554fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9aa6c85-02e7-40bf-b0b8-de846d8863b0",
   "metadata": {},
   "source": [
    "# 4. Impute values: replace outliers based on rolling average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4a532-1f90-4312-bc78-c7f1c506b91f",
   "metadata": {},
   "source": [
    "### Create col `TO_IMPUTE` \n",
    "Create `TO_IMPUTE` col from `VALUE`, and set to `NA` if value is flagged as outlier (namely, when `OUTLIER == TRUE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91adef-54d9-4ad6-beab-5d67250240d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhis2_routine_long_outliers_imputed <- dhis2_routine_long_outliers %>%\n",
    "  mutate(TO_IMPUTE = VALUE,\n",
    "         TO_IMPUTE = if_else(OUTLIER == TRUE, NA_real_, TO_IMPUTE)) \n",
    "\n",
    "head(dhis2_routine_long_outliers_imputed, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ca92e-60ff-41ba-8c98-be04f08701dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "dhis2_routine_long_outliers_imputed %>% filter(OUTLIER == TRUE) %>% head(., 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09063ae6-dc41-4473-bf9c-20c1f633d76d",
   "metadata": {},
   "source": [
    "### Impute: Calculate rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2688dc-6237-4521-a6d5-5e8f010a00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhis2_routine_long_outliers_imputed <- dhis2_routine_long_outliers_imputed %>%\n",
    "arrange(ADM1_ID, ADM2_ID, OU_ID, INDICATOR, PERIOD) %>%  # Ensure proper order\n",
    "    group_by(ADM1_ID, ADM2_ID, OU_ID, INDICATOR) %>%  # Group data\n",
    "    mutate(\n",
    "        MOVING_AVG = zoo::rollapply(TO_IMPUTE, \n",
    "                                    width = 3, \n",
    "                                    FUN = function(x) ceiling(mean(x, na.rm = TRUE)), \n",
    "                                    fill = NA, \n",
    "                                    align = \"center\"),\n",
    "        VALUE_IMPUTED = ifelse(is.na(TO_IMPUTE), MOVING_AVG, TO_IMPUTE)  # Replace NA with MOVING_AVG\n",
    "    ) %>%  \n",
    "    ungroup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae10237-0821-4df8-b77c-a6a63878f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim(dhis2_routine_long_outliers_imputed))\n",
    "head(dhis2_routine_long_outliers_imputed, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fc469-5043-499a-a49f-53481904e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Curiosity check: see where NaN's introduced by `zoo::rollapply()`\n",
    "# merged_data_imputation_imputed %>% filter(is.nan(VALUE_IMPUTED)) %>% head(., 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a829e-ecf3-4827-b58d-c2afa6fd9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all `NaN`s to `NA`s\n",
    "dhis2_routine_long_outliers_imputed$VALUE_IMPUTED[is.nan(dhis2_routine_long_outliers_imputed$VALUE_IMPUTED)] <- NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4dbe6-3a9b-4dff-92bd-150d2db91409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6aee907-799e-43b1-9297-36edafd552bf",
   "metadata": {},
   "source": [
    "### Replace values, and pivot wider\n",
    "More specifically:\n",
    "* replace outlier values with imputed values: simply rename `VALUE_IMPUTED` col to `VALUE`\n",
    "* pivot table to wider (return to original structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3a435-0c50-4665-a4ec-a53be2f393fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhis2_routine_imputed <- dhis2_routine_long_outliers_imputed %>%\n",
    "    mutate(VALUE = VALUE_IMPUTED) %>% # IMPUTATION_VALUE\n",
    "    select(all_of(fixed_cols), INDICATOR, VALUE) %>% # names() #  'PERIOD''YEAR''MONTH''OU''ADM1_ID''ADM2_ID''INDICATOR''VALUE'\n",
    "    pivot_wider(names_from = \"INDICATOR\", values_from = \"VALUE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7f61e-4102-4d5c-9370-619ec5d38264",
   "metadata": {},
   "source": [
    "#### Sanity check: make sure imputing does not alter the number of rows in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4cb79-6dad-4e35-9352-92058b6e503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions and log error if they don't match\n",
    "if (!isTRUE(all.equal(nrow(dhis2_routine), nrow(dhis2_routine_imputed)))) {\n",
    "  msg_error <- paste0(\n",
    "    \"Error: Nr of rows in 'dhis2_routine' (\",\n",
    "    paste(dim(dhis2_routine), collapse = \"x\"),\n",
    "    \") does not match nr of rows in 'dhis2_routine_imputed' (\",\n",
    "    paste(dim(dhis2_routine_imputed), collapse = \"x\"),\n",
    "    \").\"\n",
    "  )\n",
    "\n",
    "  if (!is.null(openhexa$current_run)) {\n",
    "    openhexa$current_run$log_error(msg_error)\n",
    "  }\n",
    "\n",
    "  stop(msg_error) # stop the script and print the error message\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a84727-d87e-49d4-9264-1cca85e5370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1e507d5-9f74-4f55-a83a-9b1b9f4e2c99",
   "metadata": {},
   "source": [
    "# 5. Export Output tables\n",
    "Export tables as .csv and .parquet files to `/data/dhis2_outliers_removal_imputation/` folder, then code in pipeline.py will handle the writing to Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b8429-d1b9-4589-b345-991af879e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data <- function(data_object, file_suffix, file_type) {\n",
    "  # Define the output directory\n",
    "  output_dir <- file.path(DATA_PATH, \"dhis2_outliers_removal_imputation\")\n",
    "\n",
    "  # Create the directory if it doesn't exist\n",
    "  if (!dir.exists(output_dir)) {\n",
    "    dir.create(output_dir, recursive = TRUE)\n",
    "  }\n",
    "\n",
    "  # Construct the file name\n",
    "  file_name <- paste0(COUNTRY_CODE, \"_routine_outliers-\", OUTLIER_METHOD, file_suffix, \".\", file_type)\n",
    "\n",
    "  # Construct the full path\n",
    "  full_path <- file.path(output_dir, file_name)\n",
    "\n",
    "  # Export the data based on file type\n",
    "  if (file_type == \"csv\") {\n",
    "    write_csv(data_object, full_path)\n",
    "  } else if (file_type == \"parquet\") {\n",
    "    arrow::write_parquet(data_object, full_path)\n",
    "  } else {\n",
    "    stop(\"Unsupported file type. Please use 'csv' or 'parquet'.\")\n",
    "  }\n",
    "\n",
    "  # Log the export\n",
    "  log_msg(paste0(\"Exported : \", full_path))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585deb9-8013-4af6-a636-58b1b1870755",
   "metadata": {},
   "source": [
    "## 5.1. Routine without outliers: `dhis2_routine_outliers_removed`\n",
    "As `XXX_routine_removed-outliers-<method_name>`.parquet/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd1e00-a7e8-47cd-8056-af7047acc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting removed data\n",
    "export_data(dhis2_routine_outliers_removed, \"_removed\", \"csv\")\n",
    "export_data(dhis2_routine_outliers_removed, \"_removed\", \"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7bbce6-097f-4897-9b84-eb40f34f553b",
   "metadata": {},
   "source": [
    "## 5.2. Routine with **imputed** values: `dhis2_routine_imputed`\n",
    "As `XXX_routine_outliers-<method_name>_imputed`.parquet/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909e864-072f-4556-9f5a-c6e2ae3e2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting imputed data\n",
    "export_data(dhis2_routine_imputed, \"_imputed\", \"csv\")\n",
    "export_data(dhis2_routine_imputed, \"_imputed\", \"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee3153-7b41-4676-9c4b-6a279491063b",
   "metadata": {},
   "source": [
    "# 6. Write to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb325cec-b795-4fb5-8836-423d29cb5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double check that {reticulate} finds the module ... \n",
    "# openhexa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964bb34-9ed6-4e3f-b862-ff347cf2fb14",
   "metadata": {},
   "source": [
    "## 6.1. Create new **dataset** (coded)\n",
    "This step could be skipped if preference for creating the Dataset manually  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cafc80-b1ee-4d88-be8f-c36c7e3dcbbe",
   "metadata": {},
   "source": [
    "Check if a dataset with slug == \"**dhis2-outliers-detection**\" already exists, if not create one.<br>\n",
    "This avoids silentily creating a new dataset with same name (yet different slug and id) at each run ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b265f7-f3c1-47d0-a7df-fd61f775a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Dataset \n",
    "# DATASET_SLUG = \"dhis2-outliers-removal-imputation\" # \"dhis2-outliers-detection\"\n",
    "# DATASET_NAME <- \"DHIS2_OUTLIERS_REMOVAL_IMPUTATION\" # \"DHIS2_OUTLIERS_DETECTION\"\n",
    "# DATASET_DESCRIPTION <- \"Routine DHIS2 data without outliers and (optional) with imputer values. Outliers removal follows flagging based on various methods - see dedicated notebook for mode details.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d542be-5193-43cd-8f36-1a7d72cbbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List all datasets \n",
    "# existing_datasets <- openhexa$workspaces$workspace$list_datasets()\n",
    "\n",
    "# # Check if a dataset with slug \"dhis2-reporting-rate\" exists (DATASET_SLUG)\n",
    "# dataset_exists <- FALSE\n",
    "# for (ds in existing_datasets) {\n",
    "#   if (ds$slug == DATASET_SLUG) {\n",
    "#     dataset_exists <- TRUE\n",
    "#     dataset <- ds  # Store the existing dataset to be used downstream\n",
    "#     break\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# # If it doesn't exist, create it \n",
    "# if (!dataset_exists) {\n",
    "#   # Define name & description (modify as needed)\n",
    "#   dataset_name <- DATASET_NAME\n",
    "#   dataset_description <- DATASET_DESCRIPTION\n",
    "  \n",
    "#   # Create the dataset\n",
    "#   dataset <- openhexa$workspaces$workspace$create_dataset(\n",
    "#     name = dataset_name,\n",
    "#     description = dataset_description\n",
    "#   )\n",
    "  \n",
    "#   print(paste(\"Created new dataset:\", dataset$slug))\n",
    "# } else {\n",
    "#   print(paste(\"Dataset already exists:\", dataset$slug))\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a728ea6c-efcb-45f3-9270-29fd0562a9d9",
   "metadata": {},
   "source": [
    "## 6.2. Assign **version** to dataset - _if_ it does not have one yet\n",
    "üö® Note: brand-new datasets don't have a version yet! Version needs to be explicitly created! <br>\n",
    "With this code a \"**v0**\" is created only if dataset doesn't have any (else it will keep its current version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e9a53-ba0b-46b9-a22f-3532c5cb4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if dataset has any versions\n",
    "# if (is.null(dataset$latest_version)) {\n",
    "#   print(\"Dataset has no versions. Creating initial version 'v0'...\")\n",
    "#   initial_version <- dataset$create_version(\"v0\")\n",
    "#   print(paste(\"Created version:\", initial_version$name))\n",
    "# } else {\n",
    "#   print(paste(\"Dataset already has versions. Latest version:\", dataset$latest_version$name))\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b428f-b773-4649-a68a-476cae4a6fe0",
   "metadata": {},
   "source": [
    "## 6.3. Define list of **files to be written** to the Dataset\n",
    "Here we're writing _all_ the files that we previously exported as `.csv` and `.parquet` files to `/data/dhis2_incidence/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8498027-fe1f-47dc-b937-7f3509d76bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTED_DATA_FOLDER = \"dhis2_outliers_removal_imputation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396bb02-dc34-4bd8-8380-7cbf7223be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the directory path (with expanded ~)\n",
    "# dir_path <- path.expand(file.path(DATA_PATH, EXPORTED_DATA_FOLDER))\n",
    "\n",
    "# # List all files in the directory\n",
    "# file_list <- list.files(dir_path, full.names = TRUE, recursive = FALSE)\n",
    "\n",
    "# # Check if there are any files\n",
    "# if (length(file_list) == 0) {\n",
    "#   stop(\"No files found in directory: \", dir_path)\n",
    "# }\n",
    "\n",
    "# # Print files to be uploaded (for debugging)\n",
    "# print(\"Files to be uploaded:\")\n",
    "# print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47a774-9199-4965-92c9-11625d0bd2a2",
   "metadata": {},
   "source": [
    "## 6.4. Create **new version** of Dataset and **write all files** to it\n",
    "At each execution of the notebook (hence at each pipeline execution):\n",
    "* **creates** a new version of the Dataset\n",
    "* **writes** all files found in `file_list` to this (latest) Dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4f89b-7a0f-4f6a-ad2e-556dc103c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Get latest dataset version name\n",
    "# latest_version_name <- dataset$latest_version$name\n",
    "# latest_version_nr <- as.numeric(gsub(\"v\", \"\", latest_version_name))\n",
    "\n",
    "# # 2. Create a new version (vX+1)\n",
    "# new_version <- dataset$create_version(paste0(\"v\", latest_version_nr + 1))\n",
    "\n",
    "# # 3. Add all files to the new version\n",
    "# for (file_path in file_list) {\n",
    "#   # Extract just the filename (without full path)\n",
    "#   filename <- basename(file_path)\n",
    "  \n",
    "#   # Upload the file\n",
    "#   new_version$add_file(file_path, filename = filename)\n",
    "  \n",
    "#   # Print confirmation\n",
    "#   print(paste(\"Uploaded:\", filename))\n",
    "# }\n",
    "\n",
    "# print(paste(\"Successfully uploaded\", length(file_list), \"files to version\", new_version$name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aec2a3-77f5-4f21-9d9f-ee513ea985ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695033ce-4ebe-45f3-b9bf-4feb935a956c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
